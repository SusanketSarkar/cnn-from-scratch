{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='fashion_mnist',\n",
      "    full_name='fashion_mnist/3.0.1',\n",
      "    description=\"\"\"\n",
      "    Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
      "    \"\"\",\n",
      "    homepage='https://github.com/zalandoresearch/fashion-mnist',\n",
      "    data_dir='/Users/susanketsarkar/tensorflow_datasets/fashion_mnist/3.0.1',\n",
      "    file_format=tfrecord,\n",
      "    download_size=Unknown size,\n",
      "    dataset_size=36.42 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@article{DBLP:journals/corr/abs-1708-07747,\n",
      "      author    = {Han Xiao and\n",
      "                   Kashif Rasul and\n",
      "                   Roland Vollgraf},\n",
      "      title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n",
      "                   Algorithms},\n",
      "      journal   = {CoRR},\n",
      "      volume    = {abs/1708.07747},\n",
      "      year      = {2017},\n",
      "      url       = {http://arxiv.org/abs/1708.07747},\n",
      "      archivePrefix = {arXiv},\n",
      "      eprint    = {1708.07747},\n",
      "      timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n",
      "      biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n",
      "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load Fashion MNIST from TensorFlow Datasets\n",
    "dataset, info = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_ds, test_ds = dataset['train'], dataset['test']\n",
    "\n",
    "# Normalize the images to range [0, 1]\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (64, 64))  # Resize to 64x64\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize\n",
    "    return image, label\n",
    "\n",
    "train_ds = train_ds.map(preprocess).batch(32)\n",
    "test_ds = test_ds.map(preprocess).batch(32)\n",
    "\n",
    "# Info about dataset\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 1)\n",
      "(64, 64, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 12:32:56.370187: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2025-01-26 12:32:56.470600: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Get the shape of a single batch from the training dataset\n",
    "for images, labels in train_ds.take(1):\n",
    "    input_shape = images.shape[1:]  # Skip batch dimension\n",
    "    print(input_shape)\n",
    "    break\n",
    "\n",
    "for images, labels in test_ds.take(1):\n",
    "    input_shape = images.shape[1:]  # Skip batch dimension\n",
    "    print(input_shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralnet import CNN\n",
    "from layers import conv, maxpool, flatten, dense\n",
    "from activation import ReLU, Sigmoid\n",
    "\n",
    "model = CNN()\n",
    "model.add(conv(input_channels = 1, filter = 32, kernel_size = (3, 3), stride = 2, padding = 1, activation = ReLU()))\n",
    "model.add(maxpool(pool_size = (2, 2), stride = 2))\n",
    "model.add(conv(filter = 64, kernel_size = (3, 3), stride = 1, padding = 1, activation = ReLU()))\n",
    "model.add(maxpool(pool_size = (2, 2), stride = 2))\n",
    "model.add(flatten())\n",
    "model.add(dense(input_size = 32, output_size = 32, activation = Sigmoid()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizer import SGD\n",
    "from loss import Loss\n",
    "\n",
    "model.compile(optimizer = SGD(learning_rate = 0.01), loss = Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
